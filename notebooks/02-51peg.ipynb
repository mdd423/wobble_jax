{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "854ca1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/wobbleenv/lib/python3.11/site-packages/jax/_src/api_util.py:174: SyntaxWarning: Jitted function has static_argnums=(3, 4), but only accepts 4 positional arguments. This warning will be replaced by an error after 2022-08-20 at the earliest.\n",
      "  warnings.warn(f\"Jitted function has {argnums_name}={argnums}, \"\n",
      "/ext3/miniconda3/envs/wobbleenv/lib/python3.11/site-packages/jax/_src/api_util.py:174: SyntaxWarning: Jitted function has static_argnums=(3, 4, 5), but only accepts 5 positional arguments. This warning will be replaced by an error after 2022-08-20 at the earliest.\n",
      "  warnings.warn(f\"Jitted function has {argnums_name}={argnums}, \"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import jabble.model\n",
    "import jabble.dataset\n",
    "import jabble.loss\n",
    "import jabble.physics \n",
    "import astropy.units as u\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize\n",
    "\n",
    "from jaxopt import GaussNewton\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "from mpl_axes_aligner import align\n",
    "import os\n",
    "import jabble.physics\n",
    "\n",
    "import jax.config\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9961a7-5035-4cc7-a8b1-1be56ad0c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "out_dir = os.path.join('..','out',today.strftime(\"%y-%m-%d\"))\n",
    "os.makedirs(out_dir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e260ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_b = h5py.File(\"../data/barnards_e2ds.hdf5\", \"r\")\n",
    "file_p = h5py.File(\"../data/51peg_e2ds.hdf5\"   , \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f12de1af-de7c-45b1-831b-e7f5a58f21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyData(jabble.dataset.Data):\n",
    "    def blockify(data,device):\n",
    "        max_ind = np.max([len(dataframe.xs) for dataframe in data])\n",
    "        xs    = np.zeros((len(data),max_ind))\n",
    "        ys    = np.zeros((len(data),max_ind))\n",
    "        yivar = np.zeros((len(data),max_ind))\n",
    "        mask  = np.ones((len(data),max_ind))\n",
    "    \n",
    "        for i,dataframe in enumerate(data):\n",
    "            frame_size = len(dataframe.xs)\n",
    "            xs[i,:frame_size]    = dataframe.xs\n",
    "            ys[i,:frame_size]    = dataframe.ys\n",
    "            yivar[i,:frame_size] = dataframe.yivar\n",
    "            mask[i,:frame_size]  = dataframe.mask\n",
    "\n",
    "        xs    = jax.device_put(jnp.array(xs),device)\n",
    "        ys    = jax.device_put(jnp.array(ys),device)\n",
    "        yivar = jax.device_put(jnp.array(yivar),device)\n",
    "        mask  = jax.device_put(jnp.array(mask,dtype=bool),device)\n",
    "\n",
    "        return xs, ys, yivar, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b00a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file,orders,device):\n",
    "    ys = []\n",
    "    xs = []\n",
    "    yivar = []\n",
    "    mask = []\n",
    "\n",
    "    init_shifts = []\n",
    "    airmass = []\n",
    "    \n",
    "    for iii in range(file[\"data\"].shape[0]):\n",
    "        for jjj in range(file[\"data\"].shape[1]):\n",
    "            ys.append(jnp.array(file[\"data\"][iii,jjj,:]))\n",
    "            xs.append(jnp.array(file[\"xs\"][iii,jjj,:]))\n",
    "            yivar.append(jnp.array(file[\"ivars\"][iii,jjj,:]))\n",
    "            mask.append(jnp.zeros(file[\"data\"][iii,jjj,:].shape,dtype=bool))\n",
    "            init_shifts.append(jabble.physics.shifts(file[\"bervs\"][jjj]))\n",
    "            airmass.append(file[\"airms\"][jjj])\n",
    "    \n",
    "    init_shifts = jnp.array(init_shifts)\n",
    "    airmass = jnp.array(airmass)\n",
    "                         \n",
    "    dataset = MyData(jabble.dataset.Data.from_lists(xs,ys,yivar,mask).dataframes)\n",
    "    dataset.to_device(device)\n",
    "    init_shifts = jax.device_put(init_shifts,device)\n",
    "    airmass = jax.device_put(airmass,device)\n",
    "\n",
    "    return dataset, init_shifts, airmass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05574233-a951-4620-be7f-802a0f01a9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_optimize(\n",
    "        self, loss, data, device_store, device_op, batch_size, options={}\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Choosen optimizer for jabble is scipy.fmin_l_bfgs_b.\n",
    "        optimizes all parameters in fit mode with respect to the loss function using jabble.Dataset\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        loss : `jabble.Loss`\n",
    "            jabble.loss object, \n",
    "        data : `jabble.Dataset`\n",
    "            jabble.Dataset, that is handed to the Loss function during optimization\n",
    "        verbose : `bool`\n",
    "            if true prints, loss, grad dot grad at every function\n",
    "        save_history : `bool`\n",
    "            if true, saves values of parameters at every function call\n",
    "        save_loss : `bool`\n",
    "            if true, saves loss array every function call of optimization\n",
    "        options : \n",
    "            additional keyword options to be passed to scipy.fmin_l_bfgs_b\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        d : `dict`\n",
    "            Results from scipy.fmin_l_bgs_b call\n",
    "        \"\"\"\n",
    "\n",
    "        func_grad = jax.value_and_grad(loss.loss_all, argnums=0)\n",
    "\n",
    "        def val_gradient_function(p, *args):\n",
    "            val, grad = func_grad(p, *args)\n",
    "\n",
    "            return np.array(val, dtype=\"f8\"), np.array(grad, dtype=\"f8\")\n",
    "        \n",
    "        # blockify dataset\n",
    "        # mask extra points added to block\n",
    "        xs, ys, yivar, mask = data.blockify(device_store)\n",
    "\n",
    "        ##########################################################\n",
    "    \n",
    "        x, f, d = scipy.optimize.fmin_l_bfgs_b(\n",
    "            val_gradient_function, self.get_parameters(), None, (xs,ys,yivar,mask,self,device_op,batch_size), **options\n",
    "        )\n",
    "        self.results.append(d)\n",
    "        self._unpack(jax.device_put(jnp.array(x),device_op))\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9747d94-3818-419c-82db-29720adf96a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyChiSquare(jabble.loss.ChiSquare):\n",
    "    def __call__(self, p, xs, ys, yivar, mask, i, model, *args):\n",
    "        return jnp.where(~mask,yivar * (((ys - model(p,xs,i,*args))**2)),0.0)\n",
    "    \n",
    "    def loss_all(self,p,xs,ys,yivar,mask,model,device_op,batch_size,*args):\n",
    "        \n",
    "        #blockify parameters\n",
    "        #what if normalization model has different number of parameters per model\n",
    "        #anything that is going to take the epoch index needs to blockified and be the only parameter\n",
    "        #this is an issue with the normalization model because its epoch specific but the parameters vary by epoch\n",
    "        # just putting in the zero below will assume the same number of parameters as the first one\n",
    "        # not the one specified, whats the better way to do multiple epoch fitting without indices\n",
    "        \n",
    "        def _internal(xs_row,ys_row,yivar_row,mask_row,index):\n",
    "            return self(p,xs_row,ys_row,yivar_row,mask_row,index,model,*args).sum()\n",
    "\n",
    "        indices = jnp.arange(0,xs.shape[0],dtype=int)\n",
    "\n",
    "        rounds = int(np.ceil(xs.shape[0]/batch_size))\n",
    "        out = 0.0\n",
    "        for iii in range(rounds):\n",
    "            top = np.min([(iii+1)*batch_size,xs.shape[0]])\n",
    "            temp = jax.vmap(_internal, in_axes=(0, 0, 0, 0, 0), out_axes=0)(jax.device_put(xs[(iii*batch_size):top],device_op), \\\n",
    "                                                                            jax.device_put(ys[(iii*batch_size):top],device_op), \\\n",
    "                                                                            jax.device_put(yivar[(iii*batch_size):top],device_op), \\\n",
    "                                                                            jax.device_put(mask[(iii*batch_size):top],device_op), \\\n",
    "                                                                            jax.device_put(indices[(iii*batch_size):top],device_op))\n",
    "            out += temp.sum()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ccb439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dataset,resolution,p_val,vel_padding,init_shifts,airmass,pts_per_wavelength,norm_p_val,device):\n",
    "    def generate_norm_grid(xs,pts_per_wavelength):\n",
    "        return np.linspace(\n",
    "            np.min(xs),np.max(xs),\n",
    "            int((np.exp(np.max(xs)) - np.exp((np.min(xs)))) * pts_per_wavelength)\n",
    "        )\n",
    "    norm_models = []\n",
    "    for dataframe in dataset:\n",
    "        norm_models.append(jabble.model.IrwinHallModel_vmap(generate_norm_grid(dataframe.xs,pts_per_wavelength),norm_p_val))\n",
    "        \n",
    "    dx = jabble.physics.delta_x(2 * resolution)\n",
    "    x_grid = np.arange(np.min(np.concatenate(dataset.xs)), np.max(np.concatenate(dataset.xs)), step=dx, dtype=\"float64\")\n",
    "    \n",
    "    model_grid = jabble.model.create_x_grid(\n",
    "        x_grid, vel_padding.to(u.m/u.s).value, 2 * resolution\n",
    "    )  \n",
    "    model = jabble.model.CompositeModel(\n",
    "        [\n",
    "            jabble.model.ShiftingModel(init_shifts),\n",
    "            jabble.model.IrwinHallModel_vmap(model_grid, p_val),\n",
    "        ]\n",
    "    ) + jabble.model.CompositeModel(\n",
    "        [\n",
    "            jabble.model.IrwinHallModel_vmap(model_grid, p_val),\n",
    "            jabble.model.StretchingModel(airmass),\n",
    "        ]\n",
    "    ) + jabble.model.NormalizationModel(norm_models)\n",
    "\n",
    "    model.to_device(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aef9643e-25c2-4172-813f-c4187e4402c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_train_cycle(model, dataset, loss):\n",
    "    # Fit Normalization\n",
    "    model.fix()\n",
    "    model.fit(2)\n",
    "    res1 = gpu_optimize(model,loss,dataset,cpus[0],cpus[0],2000)\n",
    "    print(res1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f6704c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cycle(model, dataset, loss):\n",
    "    \n",
    "    # Fit Stellar & Telluric Template\n",
    "    model.fix()\n",
    "    model.fit(0, 1)\n",
    "    model.fit(1, 0)\n",
    "    res1 = gpu_optimize(model,loss,dataset,cpus[0],gpus[0],2000)#model.optimize(loss, dataset)\n",
    "    # print(type(model[0][0].p))\n",
    "    print(res1)\n",
    "    \n",
    "    # Fit RV\n",
    "    model.fix()\n",
    "    model.fit(0, 0)\n",
    "    res1 = gpu_optimize(model,loss,dataset,cpus[0],gpus[0],2000)# model.optimize(loss, dataset)\n",
    "    # print(type(model_p[0][0].p))\n",
    "    print(res1)\n",
    "\n",
    "    # RV Parabola Fit\n",
    "    # model.fix()\n",
    "    # shift_search = jabble.physics.shifts(np.linspace(-10, 10, 100))\n",
    "    # model[0][0].parabola_fit(shift_search, loss, model, dataset)\n",
    "    # print(type(model_p[0][0].p))\n",
    "\n",
    "    # Fit Everything\n",
    "    model.fix()\n",
    "    model.fit(0, 0)\n",
    "    model.fit(0, 1)\n",
    "    model.fit(1, 0)\n",
    "    model.fit(2)\n",
    "    res1 = gpu_optimize(model,loss,dataset,cpus[0],gpus[0],2000)#model.optimize(loss, dataset)\n",
    "    # print(type(model_p[0][0].p))\n",
    "    print(res1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d730833b-c2f3-40e0-821e-d179c37781b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus = jax.devices(\"cpu\")\n",
    "# gpus = jax.devices(\"gpu\")\n",
    "loss = MyChiSquare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "437c441f-ed1a-41c0-9d65-5f7f0f6a6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 115_000\n",
    "p_val = 2\n",
    "vel_padding = 100 * u.km / u.s\n",
    "\n",
    "pts_per_wavelength = 1/10\n",
    "norm_p_val = 4\n",
    "\n",
    "model_names = [os.path.join(out_dir,'barnards.mdl'), os.path.join(out_dir,'peg51.mdl')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df1ca73d-eda7-4104-b51e-6bb90f2e5b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(file,model_name):\n",
    "    dataset, shifts, airmass = get_dataset(file,0,cpus[0])\n",
    "    \n",
    "    model = jabble.model.load(model_name)\n",
    "    model.to_device(gpus[0])\n",
    "    model = train_cycle(model, dataset, loss)\n",
    "    jabble.model.save(model_name,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75992fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prerun(file,model_name):\n",
    "    dataset, shifts, airmass = get_dataset(file,0,cpus[0])\n",
    "\n",
    "    model = get_model(dataset,resolution,p_val,vel_padding,shifts,airmass,pts_per_wavelength,norm_p_val,cpus[0])\n",
    "    model = pre_train_cycle(model, dataset, loss)\n",
    "    jabble.model.save(model_name,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67282b72-7f5e-43c7-ab82-c85bde9948e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name,file in zip(model_names,[file_b,file_p]):\n",
    "    prerun(file,model_name)\n",
    "    # run(file,model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6654272-8ed1-4917-ba8d-8c50ba250662",
   "metadata": {},
   "source": [
    "5577 night sky line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8278831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelname = 'barnardsvmapmodel1.mdl'\n",
    "# # model = jabble.model.load(modelname)\n",
    "# jabble.model.save(modelname,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ef9439-9570-4979-8330-be3ef582835f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(model,dataset,init_shifts,filename):\n",
    "    x_window = np.log(4550) - np.log(4549)\n",
    "    lmin = np.exp(dataset.xs[0,500])\n",
    "    lmax = np.exp(dataset.xs[0,1500])\n",
    "    lrange = np.arange(lmin,lmax,5)\n",
    "    plt_unit = u.Angstrom\n",
    "    epoches = 25\n",
    "    r_plots = 5\n",
    "\n",
    "    vel_epoch = 5\n",
    "    fig, axes = plt.subplots(\n",
    "        epoches // r_plots,\n",
    "        r_plots,\n",
    "        figsize=(8, 8),\n",
    "        sharex=False,\n",
    "        sharey=True,\n",
    "        facecolor=(1, 1, 1),\n",
    "        dpi=200,\n",
    "    )\n",
    "    # fig.suptitle(filenames[model_num])\n",
    "    for plt_epoch in range((epoches // r_plots) * r_plots):\n",
    "        xplot = np.linspace(np.log(lmin), np.log(lmax), dataset.xs.shape[1] * 10)\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].set_xlim(\n",
    "            xplot.min() + model[0][0].p[plt_epoch],\n",
    "            xplot.max() + model[0][0].p[plt_epoch],\n",
    "        )\n",
    "\n",
    "        # model_set[model_num].fix()\n",
    "        # model_set[model_num].fit(0)\n",
    "        # rv_model_deriv = jax.jacfwd(model_set[model_num], argnums=0)(model_set[model_num].get_parameters(),dataset.xs[plt_epoch,:],plt_epoch)\n",
    "        # rv_loss_deriv = jax.jacfwd(loss, argnums=0)(model_set[model_num].get_parameters(),datasets[0],vel_epoch,model_set[model_num])\n",
    "\n",
    "        model.fix()\n",
    "\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].errorbar(\n",
    "            dataset.xs[plt_epoch, :],\n",
    "            dataset.ys[plt_epoch, :],\n",
    "            dataset.yerr[plt_epoch, :],\n",
    "            fmt=\".k\",\n",
    "            elinewidth=1.2,\n",
    "            zorder=1,\n",
    "            alpha=0.5,\n",
    "            ms=3,\n",
    "        )\n",
    "\n",
    "        # true_model.fix()\n",
    "\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].plot(\n",
    "            xplot,\n",
    "            model([], xplot, plt_epoch),\n",
    "            \"-r\",\n",
    "            linewidth=1.2,\n",
    "            zorder=2,\n",
    "            alpha=0.5,\n",
    "            ms=6,\n",
    "        )\n",
    "        # axes[plt_epoch // r_plots, plt_epoch % r_plots].plot(xplot,true_model([],xplot,plt_epoch),'-r',linewidth=1.2,zorder=1,alpha=0.5,ms=6)\n",
    "\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].set_ylim(-2, 1)\n",
    "        #         axes[i,j].set_yticks([])\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].set_xticks(np.log(lrange))\n",
    "        axes[plt_epoch // r_plots, plt_epoch % r_plots].set_xticklabels(\n",
    "            [\"{:2.0f}\".format(x) for x in lrange]\n",
    "        )\n",
    "\n",
    "        res_ax = axes[plt_epoch // r_plots, plt_epoch % r_plots].twinx()\n",
    "        residual = loss(\n",
    "            model.get_parameters(),\n",
    "            dataset,\n",
    "            plt_epoch,\n",
    "            model,\n",
    "        )\n",
    "        res_ax.step(\n",
    "            dataset.xs[plt_epoch, :], residual, where=\"mid\", alpha=0.3, label=\"residual\"\n",
    "        )\n",
    "        res_ax.set_ylim(0.0, 20)\n",
    "        res_ax.set_yticks([])\n",
    "        # res_ax.step(model_set[i][j][1].xs+model_set[i][j][0].p[plt_epoch],\\\n",
    "        #             model_set[i][j].results[-2]['grad'][:],\\\n",
    "        #             where='mid',alpha=0.4,label='residual',zorder=-1)\n",
    "        # res_ax.set_yticks([])\n",
    "\n",
    "        # res_ax.step(x_grid,\\\n",
    "        #             rv_model_deriv[:,plt_epoch],\\\n",
    "        #             where='mid',alpha=0.4,label='RV Derivative',zorder=-1)\n",
    "\n",
    "        #     res_ax.step(x_grid,\\\n",
    "        #                 rv_loss_deriv[:,plt_epoch],\\\n",
    "        #                 where='mid',alpha=0.4,label='RV Derivative',zorder=-1)\n",
    "\n",
    "        #     align_yaxis(, 0, , 0)\n",
    "\n",
    "        align.yaxes(\n",
    "            axes[plt_epoch // r_plots, plt_epoch % r_plots], 0.0, res_ax, 0.0, 2.0 / 3.0\n",
    "        )\n",
    "\n",
    "    # res.get_shared_y_axes().join(ax1, ax3)\n",
    "    fig.text(0.5, 0.04, \"$\\lambda$\", ha=\"center\")\n",
    "    fig.text(0.04, 0.5, \"y\", va=\"center\", rotation=\"vertical\")\n",
    "    # fig.text(0.96, 0.5, '$d \\L /d \\delta x$', va='center', rotation=270)\n",
    "    # fig.text(0.96, 0.5, '$d f_{{{ji}}} /d \\delta x_k$', va='center', rotation=270)\n",
    "    fig.text(0.96, 0.5, \"residuals\", va=\"center\", rotation=270)\n",
    "\n",
    "    plt.savefig(\n",
    "        os.path.join(out_dir, \"02-res_{}.png\".format(filename)),\n",
    "        dpi=300,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8f735-8aca-4ee1-b4da-ea56f90eaa10",
   "metadata": {},
   "source": [
    "6563 h alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bae852-c141-4694-bc48-e9782d1cdff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['51peg','barnards']\n",
    "make_plot(model_b,dataset_b,shifts_b,filenames[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5806f-2751-40e3-828f-48bcde270614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv_plot(model_set,datasets,shift_set,filenames,file_set):\n",
    "    fig, ax = plt.subplots(\n",
    "        len(model_set),\n",
    "        figsize=(8, 8),\n",
    "        facecolor=(1, 1, 1),\n",
    "        dpi=300,\n",
    "        sharey=True,\n",
    "    )\n",
    "     \n",
    "    for i in range(len(model_set)):\n",
    "        velocities = jabble.physics.velocities(shift_set[i]) * u.m/u.s\n",
    "        epoches = datasets[i].xs.shape[0]\n",
    "        epoch_range = np.arange(0, epoches, dtype=int)\n",
    "        fischer_information = np.zeros(epoches)\n",
    "        for e_num in range(epoches):\n",
    "            model_set[i].fix()\n",
    "            model_set[i].fit(0,0)\n",
    "            temp = jax.jacfwd(model_set[i], argnums=0)(model_set[i].get_parameters(),datasets[i].xs[e_num,:],e_num)\n",
    "            # print(temp.shape)\n",
    "            fischer_information[e_num] = jnp.dot(\n",
    "                temp[:, e_num] ** 2, datasets[i].yivar[e_num, :]\n",
    "            )\n",
    "    \n",
    "        dvddx = jnp.array(\n",
    "            [jax.grad(jabble.physics.velocities)(x) for x in model_set[i][0][0].p]\n",
    "        )\n",
    "        verr = np.sqrt(1 / fischer_information) * dvddx\n",
    "        estimate_vel = jabble.physics.velocities(model_set[i][0][0].p)\n",
    "        tv = velocities.to(u.m/u.s).value - velocities.to(u.m/u.s).value.mean()\n",
    "        ev = estimate_vel - estimate_vel.mean()\n",
    "        ax[i].errorbar(\n",
    "            epoch_range,\n",
    "            tv - tv,\n",
    "            yerr=file_set[i][\"pipeline_sigmas\"][:],\n",
    "            fmt=\".r\",\n",
    "            elinewidth=2.2,\n",
    "            zorder=1,\n",
    "            alpha=0.5,\n",
    "            ms=6,\n",
    "        )\n",
    "    \n",
    "        ax[i].errorbar(epoch_range,tv - ev,yerr=verr,fmt='.k',elinewidth=2.2,zorder=1,alpha=0.5,ms=6)\n",
    "    \n",
    "        ax[i].set_title('{}'.format(filenames[i], model_set[i][1][0].p_val))\n",
    "        ax[i].set_xlim(-0.5, epoches - 0.5)\n",
    "    fig.text(0.04, 0.5, \"$v_{truth} - v_{est}$ [$m/s$]\", va=\"center\", rotation=\"vertical\")\n",
    "    fig.text(0.5, 0.04, \"epochs\", ha=\"center\")\n",
    "    plt.savefig(os.path.join(out_dir, \"02-dv-barn-51peg.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d731a5-2510-4846-a9fb-05bcfdf46c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_set = [model_p,  model_b]\n",
    "datasets  = [dataset_p,dataset_b]\n",
    "shift_set = [shifts_p, shifts_b]\n",
    "file_set  = [file_p,   file_b]\n",
    "rv_plot(model_set,datasets,shift_set,filenames,file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f721096-7dd7-4376-93e7-8b41bfadab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_better_plot(model_set,datasets,file_set):\n",
    "    \n",
    "\n",
    "    fig, axes = plt.subplots(2*len(model_set),4,figsize=(4*4,4*len(model_set)),sharex=True,facecolor=(1, 1, 1),dpi=200,height_ratios=[4,1]*len(model_set))\n",
    "    \n",
    "    for jj,(model,dataset,file) in enumerate(zip(model_set,datasets,file_set)):\n",
    "        x_window = np.log(4550) - np.log(4549)\n",
    "        lmin = np.exp(dataset.xs[0,0])\n",
    "        lmax = np.exp(dataset.xs[0,2000])\n",
    "        lrange = np.arange(lmin,lmax,5)\n",
    "        sort_airmasses = np.argsort(np.array(file['airms'][:]))\n",
    "        plt_epochs = np.concatenate((sort_airmasses[:2],sort_airmasses[-2:]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        offset = 1.0\n",
    "        xplot = np.linspace(np.log(lmin)-x_window,np.log(lmax)+x_window,dataset.xs.shape[1]*10)\n",
    "        for ii,plt_epoch in enumerate(plt_epochs):\n",
    "            axes[2*jj,ii].set_xlim(xplot.min()+model[0][0].p[plt_epoch],xplot.max()+model[0][0].p[plt_epoch])\n",
    "            \n",
    "            model.fix()\n",
    "            \n",
    "            axes[2*jj,ii].errorbar(dataset.xs[plt_epoch,:],dataset.ys[plt_epoch,:],\\\n",
    "                                     dataset.yerr[plt_epoch,:],fmt='.k',elinewidth=1.2,zorder=1,alpha=0.5,ms=3)\n",
    "            \n",
    "            axes[2*jj,ii].plot(xplot,offset + model[0]([],xplot,plt_epoch),'-r',linewidth=1.2,zorder=2,alpha=0.7,ms=6)\n",
    "            axes[2*jj,ii].plot(xplot,2*offset + model[1]([],xplot,plt_epoch),'-b',linewidth=1.2,zorder=2,alpha=0.7,ms=6)\n",
    "            axes[2*jj,ii].plot(xplot,model[2]([],xplot,plt_epoch),'-m',linewidth=1.2,zorder=3,alpha=0.7,ms=6)\n",
    "            \n",
    "            # axes[0,ii].plot(xplot,2*offset + model[1]([],xplot,plt_epoch),'-b',linewidth=1.2,zorder=2,alpha=0.7,ms=6)\n",
    "            # axes[0,ii].plot(xplot,offset + model([],xplot,plt_epoch),'-g',linewidth=1.2,zorder=2,alpha=0.7,ms=6)\n",
    "            # axes[plt_epoch // r_plots, plt_epoch % r_plots].plot(xplot,true_model([],xplot,plt_epoch),'-r',linewidth=1.2,zorder=1,alpha=0.5,ms=6)\n",
    "            \n",
    "            \n",
    "            axes[2*jj,ii].set_ylim(-2,3)\n",
    "            axes[2*jj,ii].set_xticks([])\n",
    "            # axes[0].set_yticks([])\n",
    "            axes[2*jj+1,ii].set_xticks(np.log(lrange))\n",
    "            axes[2*jj+1,ii].set_xticklabels(['{:2.0f}'.format(x) for x in lrange])\n",
    "            \n",
    "            axes[2*jj+1,ii].plot(dataset.xs[plt_epoch,:],dataset.ys[plt_epoch,:] - model([],dataset.xs[plt_epoch,:],plt_epoch),'.k',alpha=0.4,ms=1)\n",
    "            \n",
    "            axes[2*jj+1,ii].set_ylim(-0.1,0.1)\n",
    "            axes[2*jj,ii].set_title('airmass = {}'.format(file['airms'][:][plt_epoch]))\n",
    "        # res_ax = axes[plt_epoch // r_plots, plt_epoch % r_plots].twinx()\n",
    "        # residual = loss(model_set[model_num].get_parameters(),dataset,plt_epoch,model_set[model_num])\n",
    "        # res_ax.step(dataset.xs[plt_epoch,:],residual,where='mid',alpha=0.3,label='residual')\n",
    "        # res_ax.set_ylim(0.0,20)\n",
    "        # res_ax.set_yticks([])\n",
    "        # res_ax.step(model_set[i][j][1].xs+model_set[i][j][0].p[plt_epoch],\\\n",
    "        #             model_set[i][j].results[-2]['grad'][:],\\\n",
    "        #             where='mid',alpha=0.4,label='residual',zorder=-1)\n",
    "        # res_ax.set_yticks([])\n",
    "        \n",
    "        # res_ax.step(x_grid,\\\n",
    "        #             rv_model_deriv[:,plt_epoch],\\\n",
    "        #             where='mid',alpha=0.4,label='RV Derivative',zorder=-1)\n",
    "            \n",
    "        #     res_ax.step(x_grid,\\\n",
    "        #                 rv_loss_deriv[:,plt_epoch],\\\n",
    "        #                 where='mid',alpha=0.4,label='RV Derivative',zorder=-1)\n",
    "            \n",
    "        #     align_yaxis(, 0, , 0)\n",
    "            \n",
    "            # align.yaxes(axes[plt_epoch // r_plots, plt_epoch % r_plots], 0.0, res_ax, 0.0, 2./3.)\n",
    "        \n",
    "        # res.get_shared_y_axes().join(ax1, ax3)\n",
    "        fig.text(0.5, 0.04, '$\\lambda$', ha='center')\n",
    "        # fig.text(0.04, 0.5, 'y', va='center', rotation='vertical')\n",
    "        # fig.text(0.96, 0.5, '$d \\L /d \\delta x$', va='center', rotation=270)\n",
    "        # fig.text(0.96, 0.5, '$d f_{{{ji}}} /d \\delta x_k$', va='center', rotation=270)\n",
    "        # fig.text(0.96, 0.5, 'residuals', va='center', rotation=270)\n",
    "    \n",
    "    plt.savefig(os.path.join(out_dir,'02-full-barn-51peg.png'),dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04116c4-5bcc-473c-9323-90f440ebd983",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_better_plot(model_set,datasets,file_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c24bb-452d-4aec-87ea-78c1000000d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e991d2-9c6e-449b-8c34-b9989fa1cbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tell_loss = [[],[]]\n",
    "for jjj, (dataset, model) in enumerate(zip(datasets,model_set)):\n",
    "    for iii in range(dataset.ys.shape[0]):\n",
    "        tell_loss[jjj].append(loss([],dataset,iii,model[0]).sum())\n",
    "\n",
    "plt.plot(np.array(file_p['airms'][:]),tell_loss[0],'.k',label='51 peg')\n",
    "plt.plot(np.array(file_b['airms'][:]),tell_loss[1],'.r',label='barnards')\n",
    "# plt.ylim(0.0,5e4)\n",
    "\n",
    "# plt.plot(np.array(file_p['airms'][:]),model_p[1][1].p,'.k',label='51 peg')\n",
    "# plt.plot(np.array(file_b['airms'][:]),model_b[1][1].p,'.r',label='barnards')\n",
    "plt.xlabel('airmass')\n",
    "plt.ylabel('$\\Sigma_* (y_* - \\hat{y}_s(x_*)) I_{y*}$')\n",
    "# plt.plot()\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'02-airmass_loss.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cecc1d-a1f4-45fb-9bcd-b320c59182e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(file_p['airms'][:]),model_p[1][1].p,'.k',label='51 peg')\n",
    "plt.plot(np.array(file_b['airms'][:]),model_b[1][1].p,'.r',label='barnards')\n",
    "plt.xlabel('airmass')\n",
    "plt.ylabel('~a')\n",
    "x_space = np.linspace(np.min(np.array(file_b['airms'][:])),np.max(np.array(file_b['airms'][:])))\n",
    "plt.plot(x_space,x_space,'-.k',alpha=0.3)\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(out_dir,'02-airmass_an.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb2dd7d-b813-4d62-a105-87bc9806bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,figsize=(4,4),sharex=True,facecolor=(1, 1, 1),dpi=200)\n",
    "\n",
    "plt_epoch = 10\n",
    "x_window = np.log(4550) - np.log(4549)\n",
    "lmin = np.exp(dataset_p.xs[0,500])\n",
    "lmax = np.exp(dataset_p.xs[0,1500])\n",
    "lrange = np.arange(lmin,lmax,5)\n",
    "xplot = np.linspace(np.log(lmin)-x_window,np.log(lmax)+x_window,dataset_p.xs.shape[1]*10)\n",
    "axes.plot(xplot,model_p[1]([],xplot,plt_epoch),'-b',linewidth=1.2,zorder=2,alpha=0.6,ms=6,label='51 peg')\n",
    "axes.plot(xplot,0.05 + model_b[1]([],xplot,plt_epoch),'-r',linewidth=1.2,zorder=2,alpha=0.6,ms=6,label='barnard')\n",
    "axes.legend()\n",
    "\n",
    "axes.set_ylim(-0.2,0.1)\n",
    "axes.set_xticks([])\n",
    "axes.set_ylabel('log flux + offset')\n",
    "axes.set_xlabel('$\\lambda$')\n",
    "axes.set_xticks(np.log(lrange))\n",
    "axes.set_xticklabels(['{:2.0f}'.format(x) for x in lrange])\n",
    "plt.title('just tellurics')\n",
    "plt.savefig(os.path.join(out_dir,'02-airmass-tell.png'),dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07406b9-398f-4f2e-b5f7-64a7dc12c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_p.fix()\n",
    "# model_p.fit(0,1)\n",
    "# e_num = 0\n",
    "# dudth = jax.jacfwd(model_p, argnums=0)(model_p.get_parameters(),dataset_p.xs[e_num,:],e_num)\n",
    "# ith   = dudth * dataset.yivar * dudth.T\n",
    "# print(dudth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a173f-f1bb-4a7c-89f9-dfa053f51f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cd0c5-474a-4d94-9746-4a733eeaee4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variation_info(self,model,dataset):\n",
    "    f_info = np.zeros(dataset.xs.shape)\n",
    "    model.fix()\n",
    "    self.fit()\n",
    "    for e_num in range(dataset.xs.shape[0]):\n",
    "        duddx = jax.jacfwd(model, argnums=0)(model.get_parameters(),dataset.xs[e_num,:],e_num)\n",
    "        f_info[e_num,:] =  jnp.dot(duddx[:,e_num]**2,dataset.yivar[e_num,:])\n",
    "    return f_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
